{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "cf3e0224",
      "metadata": {
        "id": "cf3e0224"
      },
      "source": [
        "# Effective Agent Patterns with **LangGraph** + Groq\n",
        "\n",
        "This Colab demonstrates **all seven artefacts** referenced in Anthropic’s *Building Effective Agents* framework and the LangGraph tutorial:\n",
        "\n",
        "| Layer | Pattern / Artefact | Section |\n",
        "|-------|--------------------|---------|\n",
        "| Building‑block | **Augmented LLM (Tool Use)** | 1 |\n",
        "| Workflows | Prompt‑Chaining, Parallelization, Routing, Orchestrator‑Worker, Evaluator‑Optimizer | 2‑6 |\n",
        "| Agent archetype | **ReAct Agent** (autonomous, tool‑calling loop) | 7 |\n",
        "\n",
        "The notebook auto‑logs every run to **LangSmith**, giving you shareable debug traces for recording.\n",
        "\n",
        "> **Prerequisites**\n",
        "> * A Groq Cloud key in Colab’s Secrets (`GROQ_API_KEY`).\n",
        "> * *(Optional)* A LangSmith API key (`LANGCHAIN_API_KEY`).  \n",
        "> * GPU runtime is **not** required.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "47be351e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47be351e",
        "outputId": "0236ad97-328d-4c38-e1dd-7a233bb0f3c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (25.0.1)\n",
            "Requirement already satisfied: langgraph<0.4,>=0.3.31 in /usr/local/lib/python3.11/dist-packages (0.3.31)\n",
            "Requirement already satisfied: langchain-groq>=0.3.2 in /usr/local/lib/python3.11/dist-packages (0.3.2)\n",
            "Requirement already satisfied: langsmith in /usr/local/lib/python3.11/dist-packages (0.3.31)\n",
            "Requirement already satisfied: langchain-core<0.4,>=0.1 in /usr/local/lib/python3.11/dist-packages (from langgraph<0.4,>=0.3.31) (0.3.52)\n",
            "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.0.10 in /usr/local/lib/python3.11/dist-packages (from langgraph<0.4,>=0.3.31) (2.0.24)\n",
            "Requirement already satisfied: langgraph-prebuilt<0.2,>=0.1.8 in /usr/local/lib/python3.11/dist-packages (from langgraph<0.4,>=0.3.31) (0.1.8)\n",
            "Requirement already satisfied: langgraph-sdk<0.2.0,>=0.1.42 in /usr/local/lib/python3.11/dist-packages (from langgraph<0.4,>=0.3.31) (0.1.61)\n",
            "Requirement already satisfied: xxhash<4.0.0,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from langgraph<0.4,>=0.3.31) (3.5.0)\n",
            "Requirement already satisfied: groq<1,>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from langchain-groq>=0.3.2) (0.22.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith) (0.27.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith) (3.10.16)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.11/dist-packages (from langsmith) (24.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.11/dist-packages (from langsmith) (2.11.3)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langsmith) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith) (0.23.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain-groq>=0.3.2) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain-groq>=0.3.2) (1.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain-groq>=0.3.2) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain-groq>=0.3.2) (4.13.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith) (1.0.8)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith) (0.14.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.1->langgraph<0.4,>=0.3.31) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.1->langgraph<0.4,>=0.3.31) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.1->langgraph<0.4,>=0.3.31) (6.0.2)\n",
            "Requirement already satisfied: ormsgpack<2.0.0,>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from langgraph-checkpoint<3.0.0,>=2.0.10->langgraph<0.4,>=0.3.31) (1.9.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langsmith) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langsmith) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langsmith) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith) (2.3.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.1->langgraph<0.4,>=0.3.31) (3.0.0)\n",
            "Requirement already satisfied: duckduckgo-search in /usr/local/lib/python3.11/dist-packages (8.0.1)\n",
            "Requirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.11/dist-packages (from duckduckgo-search) (8.1.8)\n",
            "Requirement already satisfied: primp>=0.15.0 in /usr/local/lib/python3.11/dist-packages (from duckduckgo-search) (0.15.0)\n",
            "Requirement already satisfied: lxml>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from duckduckgo-search) (5.3.2)\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.11/dist-packages (0.3.21)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.51 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.52)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.23 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.23)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.40)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.1.2)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.9.1)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.31)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.4.0)\n",
            "Requirement already satisfied: numpy<3,>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.19.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.23->langchain-community) (0.3.8)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.23->langchain-community) (2.11.3)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain-community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain-community) (4.13.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.27.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (3.10.16)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.23.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.1.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2025.1.31)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.2.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.0.8)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.51->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.23->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.23->langchain-community) (2.33.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
            "✅ Groq LLM initialised\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#@title 🔧 Install & initialise\n",
        "!pip install -U pip        # optional but avoids resolver quirks\n",
        "!pip install \\\n",
        "    \"langgraph>=0.3.31,<0.4\" \\\n",
        "    \"langchain-groq>=0.3.2\" \\\n",
        "    langsmith\n",
        "!pip install -U duckduckgo-search\n",
        "!pip install langchain-community  # Install the missing package\n",
        "\n",
        "from google.colab import userdata\n",
        "import os, sys\n",
        "\n",
        "# Environment variables1\n",
        "os.environ[\"GROQ_API_KEY\"] = userdata.get(\"GROQ_API_KEY\") or \"\"\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ.setdefault(\"LANGCHAIN_PROJECT\", \"agent_patterns_demo\")\n",
        "if userdata.get(\"LANGCHAIN_API_KEY\"):\n",
        "    os.environ[\"LANGCHAIN_API_KEY\"] = userdata.get(\"LANGCHAIN_API_KEY\")\n",
        "\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain_core.tools import tool\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "\n",
        "llm = ChatGroq(model_name=\"llama3-8b-8192\", temperature=0)\n",
        "print(\"✅ Groq LLM initialised\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4992426c",
      "metadata": {
        "id": "4992426c"
      },
      "source": [
        "## 1 · Augmented LLM — using tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "b63ba8a7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b63ba8a7",
        "outputId": "78a7464a-a528-47e9-9779-e92abeb99a34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: 96\n"
          ]
        }
      ],
      "source": [
        "# Define simple calculator tools with docstrings\n",
        "\n",
        "from langchain_core.messages import HumanMessage, AIMessage, ToolMessage, SystemMessage\n",
        "from langgraph.graph import StateGraph, MessagesState, START, END\n",
        "from langchain_core.tools import tool\n",
        "\n",
        "\n",
        "@tool\n",
        "def multiply(a: int, b: int) -> int:\n",
        "    \"\"\"Return the product of two integers.\"\"\"\n",
        "    return a * b\n",
        "\n",
        "@tool\n",
        "def add(a: int, b: int) -> int:\n",
        "    \"\"\"Return the sum of two integers.\"\"\"\n",
        "    return a + b\n",
        "\n",
        "@tool\n",
        "def divide(a: int, b: int) -> float:\n",
        "    \"\"\"Divide a by b and return a float (raises if b == 0).\"\"\"\n",
        "    return a / b\n",
        "\n",
        "\n",
        "tools = [multiply, add, divide]\n",
        "llm_tools = llm.bind_tools(tools)\n",
        "tools_map = {t.name: t for t in tools}\n",
        "\n",
        "# 2) LLM node: ALWAYS prepend a SystemMessage\n",
        "def call_llm(state: MessagesState) -> dict:\n",
        "    system = SystemMessage(\n",
        "        content=(\n",
        "            \"You are a calculator agent. \"\n",
        "            \"You must call the provided tools for every single operation in sequence. \"\n",
        "            \"Do NOT compute anything yourself.\"\n",
        "        )\n",
        "    )\n",
        "    # Build the message sequence: system → history\n",
        "    msgs = [system] + state[\"messages\"]\n",
        "    out  = llm_tools.invoke(msgs)\n",
        "    return {\"messages\": [out]}\n",
        "\n",
        "# 3) Tool node: same as before\n",
        "def call_tool(state: MessagesState) -> dict:\n",
        "    \"\"\"Execute each pending tool_call using the tool’s raw Python function.\"\"\"\n",
        "    last      = state[\"messages\"][-1]\n",
        "    results   = []\n",
        "    # tc['name'] is the tool name, tc['args'] is a dict of keyword args\n",
        "    for tc in getattr(last, \"tool_calls\", []):\n",
        "        tool_fn   = tools_map[tc[\"name\"]].func     # get the Python function\n",
        "        output    = tool_fn(**tc[\"args\"])          # call it directly\n",
        "        results.append(\n",
        "            ToolMessage(content=str(output), tool_call_id=tc[\"id\"])\n",
        "        )\n",
        "    return {\"messages\": results}\n",
        "\n",
        "# 4) Dispatcher: unchanged\n",
        "def dispatcher(state: MessagesState) -> str:\n",
        "    last = state[\"messages\"][-1]\n",
        "    if isinstance(last, ToolMessage):\n",
        "        return \"llm\"\n",
        "    if getattr(last, \"tool_calls\", None):\n",
        "        return \"tool\"\n",
        "    return END\n",
        "\n",
        "# 5) Build & invoke\n",
        "g = StateGraph(MessagesState)\n",
        "g.add_node(\"llm\",  call_llm)\n",
        "g.add_node(\"tool\", call_tool)\n",
        "g.add_edge(START,      \"llm\")\n",
        "g.add_conditional_edges(\"llm\", dispatcher, {\"tool\":\"tool\",\"llm\":\"llm\",END:END})\n",
        "g.add_edge(\"tool\",     \"llm\")\n",
        "\n",
        "agent = g.compile()\n",
        "state = agent.invoke({\"messages\":[HumanMessage(content=\"What is 9 * 8 / 6?\")]})\n",
        "state = agent.invoke({\n",
        "    \"messages\": [ HumanMessage(content=\"What is 9 * 8 / 6?\") ]\n",
        "})\n",
        "\n",
        "# Find the last tool output\n",
        "answer = None\n",
        "for msg in reversed(state[\"messages\"]):\n",
        "    if isinstance(msg, ToolMessage):\n",
        "        answer = msg.content\n",
        "        break\n",
        "\n",
        "print(\"Answer:\", answer)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e66cb667",
      "metadata": {
        "id": "e66cb667"
      },
      "source": [
        "## 2 · Prompt‑Chaining\n",
        "\n",
        "Break a single task into deterministic sequential sub‑tasks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "dd32caac",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dd32caac",
        "outputId": "b36c7915-4a77-4e1c-a4e5-cb05898d598a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I love it! The added humor is great! The puns are clever and well-executed. I think it's perfect just the way it is.\n",
            "\n",
            "The only thing I might suggest is adding a punchline or a final twist to really drive the humor home. For example:\n",
            "\n",
            "\"Why did the database go to therapy?\n",
            "\n",
            "Because it was feeling a little 'fragmented' and had a lot of 'unresolved queries'! It was struggling to 'connect the dots' and was worried it would 'crash' under the pressure of its own 'data overload'! But in the end, it just needed to 'reboot' its perspective and 'update' its outlook!\"\n",
            "\n",
            "The added punchline about rebooting and updating adds a bit of extra humor and cleverness to the joke. But honestly, the original version is already great, and the added twist is just a suggestion!\n"
          ]
        }
      ],
      "source": [
        "from typing_extensions import TypedDict\n",
        "\n",
        "class State(TypedDict):\n",
        "    topic: str\n",
        "    joke: str\n",
        "    improved_joke: str\n",
        "    final_joke: str\n",
        "\n",
        "def gen(state): return {\"joke\": llm.invoke(f\"Write a short joke about {state['topic']}\").content}\n",
        "def improve(state): return {\"improved_joke\": llm.invoke(f\"Make funnier: {state['joke']}\").content}\n",
        "def polish(state): return {\"final_joke\": llm.invoke(f\"Add a twist: {state['improved_joke']}\").content}\n",
        "\n",
        "g = StateGraph(State)\n",
        "g.add_node(\"gen\", gen); g.add_node(\"improve\", improve); g.add_node(\"polish\", polish)\n",
        "g.add_edge(START,\"gen\"); g.add_edge(\"gen\",\"improve\"); g.add_edge(\"improve\",\"polish\"); g.add_edge(\"polish\",END)\n",
        "chain = g.compile()\n",
        "print(chain.invoke({\"topic\":\"databases\"})[\"final_joke\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f5379bee",
      "metadata": {
        "id": "f5379bee"
      },
      "source": [
        "## 3 · Parallelization\n",
        "\n",
        "Run independent sub‑tasks concurrently, then aggregate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "1b278363",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1b278363",
        "outputId": "42e86d35-04ca-4766-aaa0-5efe9a05768a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "As the company's data grew exponentially, they realized the need to upgrade their infrastructure to accommodate the increased demand. By migrating to a cloud computing platform, they were able to scale their operations seamlessly, reducing costs and increasing efficiency, allowing them to focus on innovation and growth.\n",
            "---\n",
            "Here is a haiku on cloud computing:\n",
            "\n",
            "Data floats on air\n",
            "Scalable, secure, and free space\n",
            "Innovation's nest\n",
            "---\n",
            "Here's one:\n",
            "\n",
            "Why did the cloud go to therapy?\n",
            "\n",
            "Because it was feeling a little \"foggy\" and wanted to \"clear the air\" about its \"storage\" issues!\n"
          ]
        }
      ],
      "source": [
        "from typing_extensions import TypedDict\n",
        "\n",
        "class PState(TypedDict):\n",
        "    topic:   str\n",
        "    poem:    str\n",
        "    story:   str\n",
        "    joke:    str\n",
        "    merged:  str\n",
        "\n",
        "def make_poem(s: PState) -> dict:\n",
        "    return {\"poem\": llm.invoke(f\"Haiku on {s['topic']}\").content}\n",
        "\n",
        "def make_story(s: PState) -> dict:\n",
        "    return {\"story\": llm.invoke(f\"Two‑sentence story on {s['topic']}\").content}\n",
        "\n",
        "def make_joke(s: PState) -> dict:\n",
        "    return {\"joke\": llm.invoke(f\"Dad joke on {s['topic']}\").content}\n",
        "\n",
        "def aggregate(s: PState) -> dict:\n",
        "    return {\"merged\": f\"{s['story']}\\n---\\n{s['poem']}\\n---\\n{s['joke']}\"}\n",
        "\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "pg = StateGraph(PState)\n",
        "\n",
        "# Use unique node IDs (avoid the exact TypedDict keys)\n",
        "pg.add_node(\"gen_poem\",  make_poem)\n",
        "pg.add_node(\"gen_story\", make_story)\n",
        "pg.add_node(\"gen_joke\",  make_joke)\n",
        "pg.add_node(\"merge_all\", aggregate)\n",
        "\n",
        "# Wire them up\n",
        "pg.add_edge(START,     \"gen_poem\")\n",
        "pg.add_edge(START,     \"gen_story\")\n",
        "pg.add_edge(START,     \"gen_joke\")\n",
        "pg.add_edge(\"gen_poem\",\"merge_all\")\n",
        "pg.add_edge(\"gen_story\",\"merge_all\")\n",
        "pg.add_edge(\"gen_joke\",\"merge_all\")\n",
        "pg.add_edge(\"merge_all\", END)\n",
        "\n",
        "result = pg.compile().invoke({\"topic\":\"cloud computing\"})\n",
        "print(result[\"merged\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09ee5394",
      "metadata": {
        "id": "09ee5394"
      },
      "source": [
        "## 4 · Routing\n",
        "\n",
        "Classify input, then dispatch to the correct specialised workflow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "bbfac336",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbfac336",
        "outputId": "512ff5dd-7e0b-46aa-c976-822f958310c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There once was a AI so fine,\n",
            "Whose learning was truly divine.\n",
            "It processed with ease,\n",
            "All the data it pleased,\n",
            "And made predictions that were sublime.\n"
          ]
        }
      ],
      "source": [
        "from pydantic import BaseModel, Field\n",
        "from typing_extensions import Literal, TypedDict\n",
        "class Route(BaseModel): step: Literal[\"poem\",\"story\",\"joke\"]=Field(...)\n",
        "\n",
        "router = llm.with_structured_output(Route)\n",
        "class RState(TypedDict): query:str; answer:str\n",
        "\n",
        "def decide(s):\n",
        "    return router.invoke(f\"Is '{s['query']}' asking for a poem, story or joke?\").step\n",
        "\n",
        "def poem(s): return {\"answer\": llm.invoke(f\"Poem: {s['query']}\").content}\n",
        "def story(s): return {\"answer\": llm.invoke(f\"Story: {s['query']}\").content}\n",
        "def joke(s): return {\"answer\": llm.invoke(f\"Joke: {s['query']}\").content}\n",
        "\n",
        "rg = StateGraph(RState)\n",
        "rg.add_conditional_edges(START, decide, {\"poem\":\"poem\",\"story\":\"story\",\"joke\":\"joke\"})\n",
        "for n,f in [(\"poem\",poem),(\"story\",story),(\"joke\",joke)]: rg.add_node(n,f); rg.add_edge(n,END)\n",
        "print(rg.compile().invoke({\"query\":\"Write a limerick about AI\"})[\"answer\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f639bdc3",
      "metadata": {
        "id": "f639bdc3"
      },
      "source": [
        "## 5 · Orchestrator‑Worker\n",
        "\n",
        "Planner decomposes the task; workers execute; synthesiser merges outputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "47dca87f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47dca87f",
        "outputId": "28995e2d-227e-49f9-da53-056e359ac0e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here is a possible introduction for a white paper on Vector DB Indexing:\n",
            "\n",
            "**Introduction**\n",
            "\n",
            "In today's data-driven world, the ability to efficiently store, retrieve, and query large amounts of data is crucial for businesses and organizations to make informed decisions and stay competitive. With the proliferation of machine learning and artificial intelligence, the volume and complexity of data have increased exponentially, making traditional database indexing techniques inadequate for many appli\n"
          ]
        }
      ],
      "source": [
        "from pydantic import BaseModel\n",
        "from typing import List\n",
        "class Section(BaseModel): title:str; description:str\n",
        "class Plan(BaseModel): sections:List[Section]\n",
        "planner = llm.with_structured_output(Plan)\n",
        "\n",
        "from typing_extensions import TypedDict\n",
        "from typing import List, Annotated\n",
        "import operator\n",
        "\n",
        "class OWState(TypedDict):\n",
        "    topic:    str\n",
        "    sections: List[Section]\n",
        "    drafts:   Annotated[List[str], operator.add]   # ← fold multiple lists via list + list\n",
        "    report:   str\n",
        "\n",
        "def orchestrate(s): return {\"sections\": planner.invoke(f\"Plan white‑paper on {s['topic']}\").sections}\n",
        "\n",
        "def worker(s):\n",
        "    sec=s[\"section\"]\n",
        "    return {\"drafts\":[llm.invoke(f\"Write section '{sec.title}': {sec.description}\").content]}\n",
        "\n",
        "from langgraph.constants import Send\n",
        "def dispatch(s): return [Send(\"write\",{\"section\":sec}) for sec in s[\"sections\"]]\n",
        "\n",
        "def synth(s): return {\"report\":\"\\n\\n\".join(s[\"drafts\"])}\n",
        "\n",
        "g = StateGraph(OWState)\n",
        "g.add_node(\"orchestrate\", orchestrate)\n",
        "g.add_node(\"write\", worker)\n",
        "g.add_node(\"synth\", synth)\n",
        "g.add_edge(START,\"orchestrate\")\n",
        "g.add_conditional_edges(\"orchestrate\", dispatch, [\"write\"])\n",
        "g.add_edge(\"write\",\"synth\"); g.add_edge(\"synth\",END)\n",
        "print(g.compile().invoke({\"topic\":\"Vector DB Indexing\"})[\"report\"][:500])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ca3bd5d",
      "metadata": {
        "id": "0ca3bd5d"
      },
      "source": [
        "## 6 · Evaluator‑Optimizer\n",
        "\n",
        "Generator ⇄ Evaluator loop until quality threshold met."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "f7405230",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7405230",
        "outputId": "eac6ec1f-e1c7-4a6c-8f2a-a5293d4d6a51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final tweet: \"Discover the power of graph-based language models! LangGraph is revolutionizing NLP by leveraging graph neural networks to analyze complex linguistic structures. Unlock new insights into language and improve your AI applications with LangGraph! #LangGraph #NLP #GraphNeuralNetworks\"\n"
          ]
        }
      ],
      "source": [
        "from pydantic import BaseModel, Field\n",
        "from typing_extensions import Literal, TypedDict\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "\n",
        "# 1) Define your feedback schema\n",
        "class Feedback(BaseModel):\n",
        "    grade:   Literal[\"good\", \"bad\"]\n",
        "    comment: str\n",
        "\n",
        "# 2) Wrap the LLM to output that schema\n",
        "eval_llm = llm.with_structured_output(Feedback)\n",
        "\n",
        "# 3) Define your agent state\n",
        "class EState(TypedDict):\n",
        "    topic:   str\n",
        "    draft:   str\n",
        "    comment: str\n",
        "    grade:   str\n",
        "\n",
        "# 4) Generation node\n",
        "def gen(state: EState) -> dict:\n",
        "    if not state.get(\"comment\"):\n",
        "        prompt = f\"Write a tweet about {state['topic']}\"\n",
        "    else:\n",
        "        prompt = (\n",
        "            f\"Rewrite the tweet about {state['topic']} \"\n",
        "            f\"considering: {state['comment']}\"\n",
        "        )\n",
        "    return {\"draft\": llm.invoke(prompt).content}\n",
        "\n",
        "# 5) Evaluation node\n",
        "def judge(state: EState) -> dict:\n",
        "    fb = eval_llm.invoke(\n",
        "        f\"Grade this tweet: '{state['draft']}'. \"\n",
        "        \"Respond with grade and feedback.\"\n",
        "    )\n",
        "    return {\"grade\": fb.grade, \"comment\": fb.comment}\n",
        "\n",
        "# 6) Routing function\n",
        "def route(state: EState) -> str:\n",
        "    # If bad, loop back to 'gen'; otherwise finish.\n",
        "    return \"gen\" if state[\"grade\"] == \"bad\" else END\n",
        "\n",
        "# 7) Wire the graph\n",
        "g = StateGraph(EState)\n",
        "g.add_node(\"gen\",   gen)\n",
        "g.add_node(\"judge\", judge)\n",
        "g.add_edge(START, \"gen\")\n",
        "g.add_edge(\"gen\",   \"judge\")\n",
        "g.add_conditional_edges(\"judge\", route, {\"gen\": \"gen\", END: END})\n",
        "\n",
        "# 8) Compile & invoke\n",
        "tweet_loop = g.compile()\n",
        "result = tweet_loop.invoke({\"topic\": \"LangGraph\"})\n",
        "print(\"Final tweet:\", result[\"draft\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c6dcca00",
      "metadata": {
        "id": "c6dcca00"
      },
      "source": [
        "## 7 · ReAct Agent (Autonomous)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "e88e00b0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e88e00b0",
        "outputId": "67c68857-dbf3-4250-f696-80b357b94768"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 champ answer: As of the 2024 season, out of the 777 drivers who have started a Formula One Grand Prix, [16] the 75 titles awarded have been won by a total of 34 different drivers. [ 8 ] [ 9 ] The first Formula One World Drivers' Champion was Giuseppe Farina in the 1950 championship and the current title holder is Max Verstappen in the 2024 season. Several drivers won't be returning in 2025; The 2024 Formula 1 World Championship, with its record calendar of 24 races, concluded on Sunday with the Abu Dhabi Grand Prix, held under the lights at ... Item 1 of 5 Lando Norris, Abu Dhabi Grand Prix. December 8, 2024. REUTERS/Ahmed Jadallah ... McLaren win constructors' title for first time since 1998 ... Sunday to end McLaren's 26-year wait for ... TEMPO.CO, Jakarta - Racing for Red Bull, Max Verstappen, successfully defended the Formula 1 champion title after finishing fifth in the Las Vegas Grand Prix at Las Vegas Strip Circuit, Nevada, on Sunday, November 24, 2024. He secured the title for the fourth consecutive time. Finishing fifth was enough for Verstappen to secure the championship as his McLaren F1 Team rival, Lando Norris, could ... Red Bull's Max Verstappen crosses the finish line in fifth place to win the 2024 Formula One World Championship Drivers' title at the Las Vegas Grand Prix [Mike Blake/Reuters] Source : News ...\n"
          ]
        }
      ],
      "source": [
        "from langchain.tools import DuckDuckGoSearchRun\n",
        "from langchain_core.tools import tool\n",
        "from langchain_core.messages import HumanMessage, SystemMessage, ToolMessage\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "\n",
        "# 3) Instantiate the real search tool\n",
        "ddg = DuckDuckGoSearchRun()   # returns top‑k snippets\n",
        "\n",
        "# 4) Wrap it so LangGraph can invoke it\n",
        "@tool\n",
        "def search_web(query: str) -> str:\n",
        "    \"\"\"Run a DuckDuckGo search and return the top results.\"\"\"\n",
        "    return ddg.run(query)\n",
        "\n",
        "# 5) Build your ReAct agent (LangGraph)\n",
        "agent = create_react_agent(\n",
        "    llm,\n",
        "    tools=[search_web],\n",
        "    prompt=(\n",
        "        \"You are a serious research assistant. \"\n",
        "        \"Whenever you need external facts, call the search_web tool. \"\n",
        "        \"Do not hallucinate or answer without using it.\"\n",
        "    )\n",
        ")\n",
        "\n",
        "# 6) Invoke it correctly (pass messages list)\n",
        "result = agent.invoke({\n",
        "    \"messages\": [\n",
        "        SystemMessage(content=\"Use search_web for any factual lookup.\"),\n",
        "        HumanMessage(content=\"Who won the 2024 Formula 1 championship?\")\n",
        "    ]\n",
        "})\n",
        "\n",
        "# 7) Extract the final ToolMessage for your answer\n",
        "for msg in reversed(result[\"messages\"]):\n",
        "    if isinstance(msg, ToolMessage):\n",
        "        print(\"F1 champ answer:\", msg.content)\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part II · CrewAI Agent Patterns Demo\n",
        "\n",
        "This section reproduces **all seven artefacts** of Anthropic’s “Building Effective Agents” within **CrewAI v0.31+** using Groq Cloud LLMs.\n",
        "\n",
        "| Layer             | Artefact                                   | CrewAI construct                                     |\n",
        "|-------------------|--------------------------------------------|------------------------------------------------------|\n",
        "| Building‑block    | Augmented LLM (Tool Use)                   | Single‐agent crew with LangChain‐wrapped tools       |\n",
        "| Workflows (5×)    | Prompt‑Chaining, Parallel, Routing, Orchestrator‑Worker, Evaluator‑Optimizer | `Process.sequential`, async tasks, templates, `Process.hierarchical`, review loop |\n",
        "| Agent archetype   | Autonomous ReAct Loop                      | `Process.autonomous`                                 |\n",
        "\n",
        "> **Prerequisites**  \n",
        "> * Groq API key stored in Colab Secrets under `GROQ_API_KEY`  \n",
        "> * GPU runtime is **not** required"
      ],
      "metadata": {
        "id": "ksveCV0bi9xA"
      },
      "id": "ksveCV0bi9xA"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 🚀 CrewAI · Augmented LLM (Tool Use)\n",
        "# Install & import\n",
        "!pip install -q \"crewai>=0.31\"\n",
        "\n",
        "from crewai.tools import tool\n",
        "from crewai import Agent, Task, Crew, Process\n",
        "from langchain_groq import ChatGroq\n",
        "\n",
        "# Initialise the Groq LLM\n",
        "# ✅ new: provider prefix + model\n",
        "from langchain_groq import ChatGroq\n",
        "\n",
        "# Tell Litellm: use the Groq provider\n",
        "llm = ChatGroq(\n",
        "    model_name=\"groq/llama3-8b-8192\",\n",
        "    temperature=0\n",
        ")"
      ],
      "metadata": {
        "id": "Us07_Psb4zwD"
      },
      "id": "Us07_Psb4zwD",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1 · Augmented LLM (Tool Use)\n",
        "\n",
        "Define simple calculator tools via LangChain’s `@tool` decorator, then wrap them in CrewAI `Tool` objects."
      ],
      "metadata": {
        "id": "nNViPlzfjQRV"
      },
      "id": "nNViPlzfjQRV"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 🛠 Define & register calculator tools\n",
        "@tool(\"Multiply\")\n",
        "def multiply(a: int, b: int) -> int:\n",
        "    \"\"\"Return the product of two integers.\"\"\"\n",
        "    return a * b\n",
        "\n",
        "@tool(\"Divide\")\n",
        "def divide(a: int, b: int) -> float:\n",
        "    \"\"\"Divide first arg by second.\"\"\"\n",
        "    return a / b\n",
        "\n",
        "# 2) Build your Agent\n",
        "assistant = Agent(\n",
        "    name=\"CalculatorAgent\",\n",
        "    role=\"Arithmetic Specialist\",\n",
        "    goal=\"Always use Multiply or Divide tools for every arithmetic step\",\n",
        "    backstory=(\n",
        "        \"You are a meticulous calculator agent. \"\n",
        "        \"Never compute in‑model—invoke Multiply or Divide for every operation.\"\n",
        "    ),\n",
        "    llm=llm,\n",
        "    tools=[multiply, divide],\n",
        "    system_prompt=\"Use your tools for all math steps.\"\n",
        ")\n",
        "print(\"✅ Agent instantiated\")\n",
        "\n",
        "\n",
        "#@title ▶️ Run the Augmented LLM demo\n",
        "# 3) Single Task + small loop to process 2 tool calls\n",
        "expr_task = Task(\n",
        "    description=\"Compute the expression '{expr}' using only the tools.\",\n",
        "    expected_output=\"A string with the final numeric result.\",\n",
        "    agent=assistant\n",
        ")\n",
        "\n",
        "calc_crew = Crew(\n",
        "    agents=[assistant],\n",
        "    tasks=[expr_task],\n",
        "    process=Process.sequential,\n",
        "    max_rounds=4\n",
        ")\n",
        "\n",
        "# 4) Kickoff\n",
        "# Option A: positional dict\n",
        "result = calc_crew.kickoff({\"expr\": \"9 * 8 / 6\"})\n",
        "print(\"Answer:\", result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 807
        },
        "id": "pMisMXFq4yHZ",
        "outputId": "a4eb60d6-91bf-4c1a-ed77-5735c6cf5ae0"
      },
      "id": "pMisMXFq4yHZ",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Agent instantiated\n",
            "\u001b[91m Received None or empty response from LLM call.\u001b[00m\n",
            "\u001b[91m An unknown error occurred. Please check the details below.\u001b[00m\n",
            "\u001b[91m Error details: Invalid response from LLM call - None or empty.\u001b[00m\n",
            "\u001b[91m An unknown error occurred. Please check the details below.\u001b[00m\n",
            "\u001b[91m Error details: Invalid response from LLM call - None or empty.\u001b[00m\n",
            "\u001b[91m Received None or empty response from LLM call.\u001b[00m\n",
            "\u001b[91m An unknown error occurred. Please check the details below.\u001b[00m\n",
            "\u001b[91m Error details: Invalid response from LLM call - None or empty.\u001b[00m\n",
            "\u001b[91m An unknown error occurred. Please check the details below.\u001b[00m\n",
            "\u001b[91m Error details: Invalid response from LLM call - None or empty.\u001b[00m\n",
            "\u001b[91m Received None or empty response from LLM call.\u001b[00m\n",
            "\u001b[91m An unknown error occurred. Please check the details below.\u001b[00m\n",
            "\u001b[91m Error details: Invalid response from LLM call - None or empty.\u001b[00m\n",
            "\u001b[91m An unknown error occurred. Please check the details below.\u001b[00m\n",
            "\u001b[91m Error details: Invalid response from LLM call - None or empty.\u001b[00m\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Invalid response from LLM call - None or empty.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/crewai/agent.py\u001b[0m in \u001b[0;36mexecute_task\u001b[0;34m(self, task, context, tools)\u001b[0m\n\u001b[1;32m    249\u001b[0m             )\n\u001b[0;32m--> 250\u001b[0;31m             result = self.agent_executor.invoke(\n\u001b[0m\u001b[1;32m    251\u001b[0m                 {\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/crewai/agents/crew_agent_executor.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/crewai/agents/crew_agent_executor.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m             \u001b[0mformatted_answer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_invoke_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/crewai/agents/crew_agent_executor.py\u001b[0m in \u001b[0;36m_invoke_loop\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    220\u001b[0m                     \u001b[0mhandle_unknown_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_printer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/crewai/agents/crew_agent_executor.py\u001b[0m in \u001b[0;36m_invoke_loop\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m                 answer = get_llm_response(\n\u001b[0m\u001b[1;32m    156\u001b[0m                     \u001b[0mllm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/crewai/utilities/agent_utils.py\u001b[0m in \u001b[0;36mget_llm_response\u001b[0;34m(llm, messages, callbacks, printer)\u001b[0m\n\u001b[1;32m    162\u001b[0m         )\n\u001b[0;32m--> 163\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid response from LLM call - None or empty.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Invalid response from LLM call - None or empty.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/crewai/agent.py\u001b[0m in \u001b[0;36mexecute_task\u001b[0;34m(self, task, context, tools)\u001b[0m\n\u001b[1;32m    249\u001b[0m             )\n\u001b[0;32m--> 250\u001b[0;31m             result = self.agent_executor.invoke(\n\u001b[0m\u001b[1;32m    251\u001b[0m                 {\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/crewai/agents/crew_agent_executor.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/crewai/agents/crew_agent_executor.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m             \u001b[0mformatted_answer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_invoke_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/crewai/agents/crew_agent_executor.py\u001b[0m in \u001b[0;36m_invoke_loop\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    220\u001b[0m                     \u001b[0mhandle_unknown_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_printer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/crewai/agents/crew_agent_executor.py\u001b[0m in \u001b[0;36m_invoke_loop\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m                 answer = get_llm_response(\n\u001b[0m\u001b[1;32m    156\u001b[0m                     \u001b[0mllm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/crewai/utilities/agent_utils.py\u001b[0m in \u001b[0;36mget_llm_response\u001b[0;34m(llm, messages, callbacks, printer)\u001b[0m\n\u001b[1;32m    162\u001b[0m         )\n\u001b[0;32m--> 163\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid response from LLM call - None or empty.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Invalid response from LLM call - None or empty.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-b2cadaa16475>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;31m# 4) Kickoff\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;31m# Option A: positional dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc_crew\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkickoff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"expr\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"9 * 8 / 6\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Answer:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/crewai/crew.py\u001b[0m in \u001b[0;36mkickoff\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mProcess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequential\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 646\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_sequential_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    647\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mProcess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhierarchical\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_hierarchical_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/crewai/crew.py\u001b[0m in \u001b[0;36m_run_sequential_process\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    756\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_sequential_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mCrewOutput\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m         \u001b[0;34m\"\"\"Executes tasks sequentially and returns the final output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 758\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execute_tasks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    759\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_hierarchical_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mCrewOutput\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/crewai/crew.py\u001b[0m in \u001b[0;36m_execute_tasks\u001b[0;34m(self, tasks, start_index, was_replayed)\u001b[0m\n\u001b[1;32m    859\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m                 \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 861\u001b[0;31m                 task_output = task.execute_sync(\n\u001b[0m\u001b[1;32m    862\u001b[0m                     \u001b[0magent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0magent_to_use\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m                     \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/crewai/task.py\u001b[0m in \u001b[0;36mexecute_sync\u001b[0;34m(self, agent, context, tools)\u001b[0m\n\u001b[1;32m    326\u001b[0m     ) -> TaskOutput:\n\u001b[1;32m    327\u001b[0m         \u001b[0;34m\"\"\"Execute the task synchronously.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execute_core\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtools\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/crewai/task.py\u001b[0m in \u001b[0;36m_execute_core\u001b[0;34m(self, agent, context, tools)\u001b[0m\n\u001b[1;32m    470\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m             \u001b[0mcrewai_event_bus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTaskFailedEvent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 472\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m  \u001b[0;31m# Re-raise the exception after emitting the event\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/crewai/task.py\u001b[0m in \u001b[0;36m_execute_core\u001b[0;34m(self, agent, context, tools)\u001b[0m\n\u001b[1;32m    390\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessed_by_agents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrole\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m             \u001b[0mcrewai_event_bus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTaskStartedEvent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m             result = agent.execute_task(\n\u001b[0m\u001b[1;32m    393\u001b[0m                 \u001b[0mtask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/crewai/agent.py\u001b[0m in \u001b[0;36mexecute_task\u001b[0;34m(self, task, context, tools)\u001b[0m\n\u001b[1;32m    279\u001b[0m                 )\n\u001b[1;32m    280\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute_task\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtools\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_rpm\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rpm_controller\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/crewai/agent.py\u001b[0m in \u001b[0;36mexecute_task\u001b[0;34m(self, task, context, tools)\u001b[0m\n\u001b[1;32m    279\u001b[0m                 )\n\u001b[1;32m    280\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute_task\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtools\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_rpm\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rpm_controller\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/crewai/agent.py\u001b[0m in \u001b[0;36mexecute_task\u001b[0;34m(self, task, context, tools)\u001b[0m\n\u001b[1;32m    278\u001b[0m                     ),\n\u001b[1;32m    279\u001b[0m                 )\n\u001b[0;32m--> 280\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute_task\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtools\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/crewai/agent.py\u001b[0m in \u001b[0;36mexecute_task\u001b[0;34m(self, task, context, tools)\u001b[0m\n\u001b[1;32m    248\u001b[0m                 ),\n\u001b[1;32m    249\u001b[0m             )\n\u001b[0;32m--> 250\u001b[0;31m             result = self.agent_executor.invoke(\n\u001b[0m\u001b[1;32m    251\u001b[0m                 {\n\u001b[1;32m    252\u001b[0m                     \u001b[0;34m\"input\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtask_prompt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/crewai/agents/crew_agent_executor.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    123\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mask_for_human_input\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/crewai/agents/crew_agent_executor.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m             \u001b[0mformatted_answer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_invoke_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             self._printer.print(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/crewai/agents/crew_agent_executor.py\u001b[0m in \u001b[0;36m_invoke_loop\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                     \u001b[0mhandle_unknown_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_printer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterations\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/crewai/agents/crew_agent_executor.py\u001b[0m in \u001b[0;36m_invoke_loop\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    153\u001b[0m                 \u001b[0menforce_rpm_limit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest_within_rpm_limit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m                 answer = get_llm_response(\n\u001b[0m\u001b[1;32m    156\u001b[0m                     \u001b[0mllm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m                     \u001b[0mmessages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/crewai/utilities/agent_utils.py\u001b[0m in \u001b[0;36mget_llm_response\u001b[0;34m(llm, messages, callbacks, printer)\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"red\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         )\n\u001b[0;32m--> 163\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid response from LLM call - None or empty.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Invalid response from LLM call - None or empty."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2 · Prompt‑Chaining (Sequential)"
      ],
      "metadata": {
        "id": "26SLFAbDjW51"
      },
      "id": "26SLFAbDjW51"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3 · Parallelization (Async)"
      ],
      "metadata": {
        "id": "B7KAuFdijfJ4"
      },
      "id": "B7KAuFdijfJ4"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4 · Routing"
      ],
      "metadata": {
        "id": "AgjER90fjhll"
      },
      "id": "AgjER90fjhll"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5 · Orchestrator‑Worker (Hierarchical)"
      ],
      "metadata": {
        "id": "1DpC92OsjkeX"
      },
      "id": "1DpC92OsjkeX"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6 · Evaluator‑Optimizer (Review Loop)"
      ],
      "metadata": {
        "id": "cDgrfzpOjnrO"
      },
      "id": "cDgrfzpOjnrO"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7 · Autonomous Agent (ReAct Loop)"
      ],
      "metadata": {
        "id": "uA-7amTHjqy9"
      },
      "id": "uA-7amTHjqy9"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}