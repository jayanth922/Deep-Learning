{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "otjftTpdOpXs",
        "outputId": "48ca3b7b-a707-42d7-ebfd-f79eccf1b895"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m475.3/475.3 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m53.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.0/442.0 kB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.4/78.4 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorstore 0.1.71 requires ml_dtypes>=0.3.1, but you have ml-dtypes 0.2.0 which is incompatible.\n",
            "tf-keras 2.18.0 requires tensorflow<2.19,>=2.18, but you have tensorflow 2.15.0 which is incompatible.\n",
            "tensorflow-text 2.18.1 requires tensorflow<2.19,>=2.18.0, but you have tensorflow 2.15.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mDownloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_1 (Flatten)         (None, 784)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 128)               100480    \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 101770 (397.54 KB)\n",
            "Trainable params: 101770 (397.54 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Detailed Model Summary:\n",
            "b'graph 1 3.6111 5.2639\\nnode 138170507941776 1.8056 4.9375 3.6111 0.65278 \"{flatten_1_input|InputLayer}|{input:|output:}|{{[(None, 28, 28)]}|{[(None, 28, 28)]}}\" solid record black lightgrey\\nnode 138170507481232 1.8056 3.7847 3.0139 0.65278 \"{flatten_1|Flatten}|{input:|output:}|{{(None, 28, 28)}|{(None, 784)}}\" solid record black lightgrey\\nnode 138170517374352 1.8056 2.6319 2.7639 0.65278 \"{dense_2|Dense}|{input:|output:}|{{(None, 784)}|{(None, 128)}}\" solid record black lightgrey\\nnode 138170509270608 1.8056 1.4792 2.9167 0.65278 \"{dropout_1|Dropout}|{input:|output:}|{{(None, 128)}|{(None, 128)}}\" solid record black lightgrey\\nnode 138170507600656 1.8056 0.32639 2.7639 0.65278 \"{dense_3|Dense}|{input:|output:}|{{(None, 128)}|{(None, 10)}}\" solid record black lightgrey\\nedge 138170507941776 138170507481232 4 1.8056 4.6162 1.8056 4.5021 1.8056 4.3702 1.8056 4.2462 solid black\\nedge 138170507481232 138170517374352 4 1.8056 3.4634 1.8056 3.3493 1.8056 3.2175 1.8056 3.0934 solid black\\nedge 138170517374352 138170509270608 4 1.8056 2.3106 1.8056 2.1966 1.8056 2.0647 1.8056 1.9406 solid black\\nedge 138170509270608 138170507600656 4 1.8056 1.1579 1.8056 1.0438 1.8056 0.91192 1.8056 0.78785 solid black\\nstop\\n'\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjayanth-kalyanam\u001b[0m (\u001b[33mjayanth-kalyanam-san-jose-state-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.6"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250220_072233-6gyynygc</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/jayanth-kalyanam-san-jose-state-university/mnist-classification/runs/6gyynygc' target=\"_blank\">rich-capybara-6</a></strong> to <a href='https://wandb.ai/jayanth-kalyanam-san-jose-state-university/mnist-classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/jayanth-kalyanam-san-jose-state-university/mnist-classification' target=\"_blank\">https://wandb.ai/jayanth-kalyanam-san-jose-state-university/mnist-classification</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/jayanth-kalyanam-san-jose-state-university/mnist-classification/runs/6gyynygc' target=\"_blank\">https://wandb.ai/jayanth-kalyanam-san-jose-state-university/mnist-classification/runs/6gyynygc</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WandbCallback is deprecated and will be removed in a future release. Please use the WandbMetricsLogger, WandbModelCheckpoint, and WandbEvalCallback callbacks instead. See https://docs.wandb.ai/guides/integrations/keras for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "365/375 [============================>.] - ETA: 0s - loss: 0.4503 - accuracy: 0.8713"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20250220_072233-6gyynygc/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r375/375 [==============================] - 3s 7ms/step - loss: 0.4457 - accuracy: 0.8728 - val_loss: 0.2086 - val_accuracy: 0.9434\n",
            "Epoch 2/15\n",
            "375/375 [==============================] - ETA: 0s - loss: 0.2124 - accuracy: 0.9386"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20250220_072233-6gyynygc/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r375/375 [==============================] - 3s 7ms/step - loss: 0.2124 - accuracy: 0.9386 - val_loss: 0.1576 - val_accuracy: 0.9563\n",
            "Epoch 3/15\n",
            "366/375 [============================>.] - ETA: 0s - loss: 0.1609 - accuracy: 0.9534"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20250220_072233-6gyynygc/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r375/375 [==============================] - 3s 9ms/step - loss: 0.1612 - accuracy: 0.9533 - val_loss: 0.1288 - val_accuracy: 0.9637\n",
            "Epoch 4/15\n",
            "373/375 [============================>.] - ETA: 0s - loss: 0.1315 - accuracy: 0.9620"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20250220_072233-6gyynygc/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r375/375 [==============================] - 2s 6ms/step - loss: 0.1318 - accuracy: 0.9619 - val_loss: 0.1118 - val_accuracy: 0.9671\n",
            "Epoch 5/15\n",
            "370/375 [============================>.] - ETA: 0s - loss: 0.1112 - accuracy: 0.9671"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20250220_072233-6gyynygc/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r375/375 [==============================] - 2s 6ms/step - loss: 0.1111 - accuracy: 0.9671 - val_loss: 0.0999 - val_accuracy: 0.9700\n",
            "Epoch 6/15\n",
            "362/375 [===========================>..] - ETA: 0s - loss: 0.0981 - accuracy: 0.9707"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20250220_072233-6gyynygc/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r375/375 [==============================] - 3s 7ms/step - loss: 0.0980 - accuracy: 0.9708 - val_loss: 0.0925 - val_accuracy: 0.9725\n",
            "Epoch 7/15\n",
            "371/375 [============================>.] - ETA: 0s - loss: 0.0859 - accuracy: 0.9743"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20250220_072233-6gyynygc/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r375/375 [==============================] - 3s 9ms/step - loss: 0.0857 - accuracy: 0.9743 - val_loss: 0.0878 - val_accuracy: 0.9752\n",
            "Epoch 8/15\n",
            "270/375 [====================>.........] - ETA: 0s - loss: 0.0756 - accuracy: 0.9768"
          ]
        }
      ],
      "source": [
        "# %% @title Environment Setup - MNIST\n",
        "!pip install -q wandb tensorflow==2.15.0\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import wandb\n",
        "from wandb.integration.keras import WandbCallback\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# %%\n",
        "# Load and preprocess MNIST data\n",
        "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
        "train_images = train_images.reshape(-1, 28, 28, 1).astype(\"float32\") / 255.0\n",
        "test_images  = test_images.reshape(-1, 28, 28, 1).astype(\"float32\") / 255.0\n",
        "\n",
        "\n",
        "\n",
        "# %%\n",
        "def create_mnist_model():\n",
        "    model = models.Sequential(name=\"sequential_1\")\n",
        "    model.add(layers.Flatten(input_shape=(28, 28), name=\"flatten_1\"))\n",
        "    model.add(layers.Dense(128, activation=\"relu\", name=\"dense_2\"))\n",
        "    model.add(layers.Dropout(0.2, name=\"dropout_1\"))\n",
        "    model.add(layers.Dense(10, activation=\"softmax\", name=\"dense_3\"))\n",
        "    return model\n",
        "\n",
        "mnist_model = create_mnist_model()\n",
        "mnist_model.summary()  # This prints the model summary with box‐drawing characters and ANSI colors\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# %%\n",
        "detailed_summary = tf.keras.utils.model_to_dot(mnist_model, show_shapes=True).create(prog='dot', format='plain')\n",
        "print(\"Detailed Model Summary:\")\n",
        "print(detailed_summary)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# %%\n",
        "wandb.init(project=\"mnist-classification\", reinit=True)\n",
        "wandb.config.update({\"learning_rate\": 0.001, \"epochs\": 15, \"batch_size\": 128})\n",
        "mnist_model.compile(optimizer=\"adam\",\n",
        "                     loss=\"sparse_categorical_crossentropy\",\n",
        "                     metrics=[\"accuracy\"])\n",
        "history_mnist = mnist_model.fit(train_images, train_labels,\n",
        "                                validation_split=0.2,\n",
        "                                epochs=15,\n",
        "                                batch_size=128,\n",
        "                                callbacks=[WandbCallback()])\n",
        "\n",
        "\n",
        "\n",
        "# %%\n",
        "test_loss, test_acc = mnist_model.evaluate(test_images, test_labels)\n",
        "y_pred_mnist = mnist_model.predict(test_images).argmax(axis=1)\n",
        "\n",
        "# Log confusion matrix using W&B\n",
        "wandb.log({\"confusion_matrix\": wandb.plot.confusion_matrix(\n",
        "    y_true=test_labels,\n",
        "    preds=y_pred_mnist,\n",
        "    class_names=[str(i) for i in range(10)]\n",
        ")})\n",
        "\n",
        "# Log a few error examples (misclassified samples)\n",
        "misclassified = (y_pred_mnist != test_labels.flatten())\n",
        "error_samples = list(zip(test_images[misclassified], y_pred_mnist[misclassified], test_labels[misclassified]))[:5]\n",
        "wandb.log({\"error_examples\": [\n",
        "    wandb.Image(img, caption=f\"Pred: {p}, True: {t}\")\n",
        "    for img, p, t in error_samples\n",
        "]})"
      ]
    }
  ]
}