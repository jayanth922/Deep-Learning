# Transformers & NLP  
**Pre-Trained Inference · Fine-Tuning · Transformer From Scratch (IMDB Sentiment)**


- **01 – Inference Pretrained** : One-line inference with a KerasNLP preset (`bert_tiny_en_uncased_sst2`)
- **02 – Fine Tune Backbone** : Fine-tune DistilBERT (or BERT-base) on an IMDB subset
- **03 – Transformer From Scratch** : Build & train a 2-layer mini-Transformer (~150 k params)

- Colab Link : [https://colab.research.google.com/drive/1XSOqSZuPlcVba_B7KjjxRFMIBEaWAZNZ?usp=sharing](https://colab.research.google.com/drive/149nApZqHcx2FqsRuRDmOEwOrjXCDERRu?usp=sharing)
- Youtube Link : https://youtu.be/xRA7B1d3sik
