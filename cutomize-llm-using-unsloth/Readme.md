# Unsloth LLM Project

Welcome to the **Unsloth LLM Project** repository! This project demonstrates the use of Unsloth and Ollama for fine-tuning large language models (LLMs) across various tasks. Each task includes a successfully run Colab notebook and an accompanying video explaining the process, input formats, datasets, and results.

## Project Overview

This repository covers the following assignment tasks:

1. **Fine-tuning**: Fine-tune four LLMs (Llama 3.1 8B, Mistral NeMo 12B, Gemma 2 9B, Phi-3.5 mini) for unique use cases (coding, chat, Q&A, summarization).
2. **Continued Pretraining**: Teach an LLM a new language using Unsloth.
3. **Chat Templates**: Implement chat templates for classification, conversational chat, extending TinyLlama's context size, and fine-tuning with multiple datasets.
4. **Reward Modeling**: Implement ORPO and DPO using Unsloth.
5. **Continued Fine-tuning**: Fine-tune from a custom checkpoint.
6. **Mental Health Chatbot**: Fine-tune a model for a mental health chatbot.
7. **Export to Ollama**: Fine-tune a model, export it to Ollama, and demonstrate inference.
